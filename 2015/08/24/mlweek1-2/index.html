

<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习week1-2 | 薛定谔的软猫</title>
  <meta name="author" content="Li Zhenye">
  
  <meta name="description" content="gcusky">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="机器学习week1-2"/>
  <meta property="og:site_name" content="薛定谔的软猫"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.ico" rel="icon" type="image/x-ico">
  <link rel="alternate" href="/atom.xml" title="薛定谔的软猫" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script src="//libs.baidu.com/jquery/1.8.0/jquery.min.js"></script>
  <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5466170a6e5af0cb8af996af9ed0ea67";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-65267116-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



</head>


<body>
  <header id="header" class="inner">
<div class="alignleft">
  <h1><a href="/">薛定谔的软猫</a></h1>
  <h2><a href="/">云山自青，清水自流。顺天而为，逆天而行。</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">首页</a></li>
    
      <li><a href="/archives">归档</a></li>
    
      <li><a href="/about">备注</a></li>
    
      <li><a href="http://ltrans.cn">ltrans</a></li>
    
	<li> <a href="/atom.xml">RSS</a> </li>


  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-08-24T09:23:15.000Z"><a href="/2015/08/24/mlweek1-2/">2015-08-24</a></time>
      
      
  
    <h1 class="title">机器学习week1-2</h1>
  

    </header>
    <div class="entry">
      
        <p><code>Coursera机器学习（Andrew Ng）笔记</code><br><code>单变量线性回归,模型表达,代价函数,梯度下降</code></p>
<h1 id="单变量线性回归(Linear_Regression_with_One_Variable)">单变量线性回归(Linear Regression with One Variable)</h1><a id="more"></a>
<h2 id="1-模型表达（Model_Representation）">1.模型表达（Model Representation）</h2><blockquote>
<p>以之前的房屋交易问题为例，假使我们回归问题的训练集（Training Set）如下表所示：</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">Size in feet<sup>2</sup>(x)</th>
<th style="text-align:center">Price($) in 1000’s(y)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2104</td>
<td style="text-align:center">460</td>
</tr>
<tr>
<td style="text-align:center">1416</td>
<td style="text-align:center">232</td>
</tr>
<tr>
<td style="text-align:center">1534</td>
<td style="text-align:center">315</td>
</tr>
<tr>
<td style="text-align:center">852</td>
<td style="text-align:center">178</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
</tbody>
</table>
<blockquote>
<p>我们将要用来描述这个回归问题的标记如下:</p>
<ul>
<li>$m$ 代表训练集中实例的数量</li>
<li>$x$ 代表特征/输入变量</li>
<li>$y$ 代表目标变量/输出变量</li>
<li>$(x,y)$ 代表训练集中的实例</li>
<li>$(x^{(i)},y^{(i)})$ 代表第 i 个观察实例</li>
<li>$h$ 代表学习算法的解决方案或函数也称为假设（hypothesis）</li>
</ul>
</blockquote>
<p><img src="http://cloud.gcusky.com/MLMOOC/ML1_9.png?imageView/2/w/450" alt=""></p>
<p>　　因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得一个假设 $h$，然后将我们要预测的房屋的尺寸作为输入变量输入给 $h$，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达 $h$？<br>　　一种可能的表达方式为：$h_θ=θ_0+θ_1x$；因为只含有一个特征/输入变量，因此这样的问题叫作<strong>单变量线性回归问题</strong>。</p>
<h2 id="2-代价函数（Cost_Function）">2.代价函数（Cost Function）</h2><table>
<thead>
<tr>
<th style="text-align:center">Hypothesis:</th>
<th style="text-align:center">$h_θ=θ_0+θ_1x$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Parameters:</td>
<td style="text-align:center">$θ_0$, $θ_0$</td>
</tr>
<tr>
<td style="text-align:center"><strong>Cost Function:</strong></td>
<td style="text-align:center">$J(θ_0,θ_1)=\frac{1}{2m}\sum\limits^m_{i=1}(h_θ(x^{(i)})-y^{(i)})^2$</td>
</tr>
<tr>
<td style="text-align:center">Goal:</td>
<td style="text-align:center">$\mathop{minimize} \limits_{θ_0,θ_1}J(θ_0,θ_1)$</td>
</tr>
</tbody>
</table>
<p><img src="http://cloud.gcusky.com/MLMOOC/ML1_10.png?imageView/2/w/450" alt=""><br>　　我们现在要做的便是为我们的模型选择合适的参数（parameters）$θ_0$和 $θ_1$，在房价问题这个例子中便是直线的斜率和在 $y$ 轴上的截距。<br>　　我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距就是<strong>建模误差（modeling error）</strong>。<br>　　我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。<br>　　即使得代价函数$J(θ_0,θ_1)=\frac{1}{2m}\sum^m_{i=1}(h_θ(x^{(i)})-y^{(i)})^2$最小。接下来我们绘制一个等高线图， $(x,y,z)$ 三个坐标分别为 $θ_0$ 和 $θ_1$和 $J(θ_0,θ_1)$：<br><img src="http://cloud.gcusky.com/MLMOOC/ML1_11.png?imageView/2/w/500" alt=""><br>　　则可以看出在三维空间中存在一个使得 $J(θ_0,θ_1)$ 最小的点。<br><img src="http://cloud.gcusky.com/MLMOOC/ML1_12.png?imageView/2/w/700" alt="其中一种拟合情况"></p>
<h2 id="3-梯度下降（Gradient_Descent）">3.梯度下降（Gradient Descent）</h2><h3 id="基本思想">基本思想</h3><blockquote>
<p>开始时我们随机选择一个参数的组合$（θ_0,θ_1,…,θ_n）$，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。 我们持续这么做直到到到一个<strong>局部最小值（local minimum）</strong>,因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是<strong>全局最小值（global minimum）</strong>,选择不同的初始参数组合，可能会找到不同的局部最小值（如下图）。</p>
</blockquote>
<p><img src="http://cloud.gcusky.com/MLMOOC/ML1_13.png?imageView/2/w/700" alt=""></p>
<h2 id="4-对线性回归运用梯度下降法">4.对线性回归运用梯度下降法</h2><h3 id="4-1梯度下降的直观理解">4.1梯度下降的直观理解</h3><blockquote>
<p>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数 $J(θ_0,θ_1)$ 的最小值。</p>
</blockquote>
<p>　　梯度下降算法：$θ_j:=θ_j-α\frac{\partial}{\partialθ_j}J(θ_0,θ_1)$<br>　　对 $θ$ 赋值，使得 $J(θ)$ 按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中 $α$ 是<strong>学习率（learning rate）</strong>，它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。<strong>注意：计算时 $θ_0$ 和 $θ_1$ 要同步更新（simultaneous update）。</strong><br><img src="http://cloud.gcusky.com/MLMOOC/ML1_14.png?imageView/2/w/600" alt=""></p>
<h3 id="4-2梯度下降的线性回归">4.2梯度下降的线性回归</h3><p>　　梯度下降算法和线性回归算法比较如图：<br><img src="http://cloud.gcusky.com/MLMOOC/ML1_16.png?imageView/2/w/600" alt=""><br>　　对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：</p>
<blockquote>
<p>$\frac{\partial}{\partialθ_j}J(θ_0,θ_1)=\frac{\partial}{\partialθ_j}\frac{1}{2m}\sum\limits^m_{i=1}(h_θ(x^{(i)})-y^{(i)})^2$</p>
</blockquote>
<p>　　$j=0$ 时：$\frac{\partial}{\partialθ_0}J(θ_0,θ_1)=\frac{1}{m}\sum\limits^m_{i=1}(h_θ(x^{(i)})-y^{(i)})$<br>　　$j=1$ 时：$\frac{\partial}{\partialθ_1}J(θ_0,θ_1)=\frac{1}{m}\sum\limits^m_{i=1}(h_θ(x^{(i)})-y^{(i)})·x^{(i)}$<br>　　则算法改写成：<br><img src="http://cloud.gcusky.com/MLMOOC/ML1_17.png?imageView/2/w/600" alt=""></p>
<p>　　拟合情况：<br><img src="http://cloud.gcusky.com/MLMOOC/ML1_18.png" alt=""><br><img src="http://cloud.gcusky.com/MLMOOC/ML1_19.png" alt=""><br><img src="http://cloud.gcusky.com/MLMOOC/ML1_20.png" alt=""></p>
<p>　　<br>参考资料<br><a href="http://mooc.guokr.com/note/12/" title="MOOC学院" target="_blank" rel="external">机器学习课笔记 —— Ryan Cheung</a><br><a href="http://mooc.guokr.com/note/16274/" title="MOOC学院" target="_blank" rel="external">机器学习教程个人笔记（V2.5）—— 黄海广</a></p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/机器学习/">机器学习</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/MOOC笔记/">MOOC笔记</a>, <a href="/tags/代价函数/">代价函数</a>, <a href="/tags/单变量线性回归/">单变量线性回归</a>, <a href="/tags/机器学习/">机器学习</a>, <a href="/tags/梯度下降/">梯度下降</a>, <a href="/tags/模型表达/">模型表达</a>
  </div>

<!-- Baidu Button BEGIN -->
<div class="bdsharebuttonbox">
<a href="#" class="bds_more" data-cmd="more"></a>
<a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
<a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a>
<a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
<a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
<a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
</div>
<script>
	window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<!-- Baidu Button END -->      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



 <nav id="pagination" >
    
    
    <a href="/2015/08/23/mlweek1-1/" class="alignright next" >下一页</a>
    
    <div class="clearfix"></div>
</nav>



<section id="comment">

<!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread" data-thread-key="/2015/08/24/mlweek1-2/"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"gcusky"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END -->  

  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form accept-charset="utf-8">
    <input type="search" results="0" placeholder="搜索">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/blog/">blog</a><small>1</small></li>
  
    <li><a href="/categories/matlab/">matlab</a><small>1</small></li>
  
    <li><a href="/categories/机器学习/">机器学习</a><small>2</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/tags/MATLAB/" style="font-size: 10px;">MATLAB</a> <a href="/tags/MOOC笔记/" style="font-size: 20px;">MOOC笔记</a> <a href="/tags/二分法/" style="font-size: 10px;">二分法</a> <a href="/tags/代价函数/" style="font-size: 10px;">代价函数</a> <a href="/tags/单变量线性回归/" style="font-size: 10px;">单变量线性回归</a> <a href="/tags/博客，文章/" style="font-size: 10px;">博客，文章</a> <a href="/tags/数值法/" style="font-size: 10px;">数值法</a> <a href="/tags/无监督学习/" style="font-size: 10px;">无监督学习</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/梯度下降/" style="font-size: 10px;">梯度下降</a> <a href="/tags/模型表达/" style="font-size: 10px;">模型表达</a> <a href="/tags/监督学习/" style="font-size: 10px;">监督学习</a> <a href="/tags/非线性方程/" style="font-size: 10px;">非线性方程</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><section>
Theme of <a href="https://github.com/zippera/lightum">Lightum</a>, Improved from <a href="https://github.com/hexojs/hexo-theme-light">Light</a>, by <a href="/">zippera</a> 
</section>
<div style="text-align:center">© gcusky.com 版权所有 ICP证：粤ICP备15063973号-2</div>
<div class="clearfix"></div>
</footer>
  <script src="//libs.baidu.com/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<script type="text/javascript">
  (function(w,d,t,u,n,s,e){
	w['SwiftypeObject']=n;
	w[n]=w[n]||function(){
		(w[n].q=w[n].q||[]).push(arguments);
	};
	s=d.createElement(t);
	e=d.getElementsByTagName(t)[0];
	s.async=1;
	s.src=u;
	e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
  _st('install','bA_qvExyytHkyGzm6rYs','2.0.0');
</script>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>



